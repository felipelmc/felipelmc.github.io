[
  {
    "objectID": "publications/publications.html",
    "href": "publications/publications.html",
    "title": "ğŸ—ƒPublications",
    "section": "",
    "text": "ğŸ“„ As relaÃ§Ãµes Executivo-Legislativo na Primeira RepÃºblica: uma anÃ¡lise das mensagens presidenciais ao Congresso (1910-1920). Mosaico. 2021.\nğŸŒ Access link\n\n\n\nğŸ“„ Fatores explicativos do apoio ou rejeiÃ§Ã£o Ã  criaÃ§Ã£o de uma polÃ­tica municipal de renda bÃ¡sica: modelando a percepÃ§Ã£o dos cariocas. 2025.\nJoint work with Jimmy Medeiros (FGV CPDOC), AntÃ´nio Mariano (FGV CPDOC), and Philippe Chaves Guedon (FGV CPDOC)."
  },
  {
    "objectID": "publications/publications.html#papers",
    "href": "publications/publications.html#papers",
    "title": "ğŸ—ƒPublications",
    "section": "",
    "text": "ğŸ“„ As relaÃ§Ãµes Executivo-Legislativo na Primeira RepÃºblica: uma anÃ¡lise das mensagens presidenciais ao Congresso (1910-1920). Mosaico. 2021.\nğŸŒ Access link\n\n\n\nğŸ“„ Fatores explicativos do apoio ou rejeiÃ§Ã£o Ã  criaÃ§Ã£o de uma polÃ­tica municipal de renda bÃ¡sica: modelando a percepÃ§Ã£o dos cariocas. 2025.\nJoint work with Jimmy Medeiros (FGV CPDOC), AntÃ´nio Mariano (FGV CPDOC), and Philippe Chaves Guedon (FGV CPDOC)."
  },
  {
    "objectID": "publications/publications.html#open-source-tools",
    "href": "publications/publications.html#open-source-tools",
    "title": "ğŸ—ƒPublications",
    "section": "Open-source tools",
    "text": "Open-source tools\nğŸ’» mape_municipios-dashboard: a dashboard to interact with one of the most complete databases with information on Brazilian municipalities, collected by MAPE. 2025.\nJoint work with Fernando Meireles (IESP-UERJ).\nğŸ”— Source code Â· ğŸŒ Access link\nğŸ’» RelicÃ¡rIA: a digital platform that combines AI and data analysis to extract and visualize information from documents. 2025.\nJoint work with Danielle Sanches de Almeida (FGV ECMI).\nğŸ”— Source code Â· ğŸŒ Access link\nğŸ’» BoticÃ¡rIA: a RAG-based conversational AI that simulates an 18th-century apothecary, providing information on medicinal practices based on historical pharmacological sources from the late 18th century. 2025.\nJoint work with Danielle Sanches de Almeida (FGV ECMI).\nğŸ”— Source code Â· ğŸŒ Access link"
  },
  {
    "objectID": "projects/scielo-summarizer/index.html",
    "href": "projects/scielo-summarizer/index.html",
    "title": "SciELO-Summarizer",
    "section": "",
    "text": "SciELO-Summarizer consists of a summarizer for scientific articles in Portuguese. It scrapes the content of the article from the SciELO website and generates a personalized summary for the user using Large Language Models (LLMs), especifically Llama3.\nTo run the project locally, you need to have both Python 3.8 or higher and Llama3 installed. It is also possible to run the project on Google Colab, following this link.\nThe program was developed during the Summer Institute in Computational Social Sciences (SICSS) 2024, hosted by FGV ECMI, Brazil, in July 2024."
  },
  {
    "objectID": "projects/scielo-summarizer/index.html#about-the-project",
    "href": "projects/scielo-summarizer/index.html#about-the-project",
    "title": "SciELO-Summarizer",
    "section": "",
    "text": "SciELO-Summarizer consists of a summarizer for scientific articles in Portuguese. It scrapes the content of the article from the SciELO website and generates a personalized summary for the user using Large Language Models (LLMs), especifically Llama3.\nTo run the project locally, you need to have both Python 3.8 or higher and Llama3 installed. It is also possible to run the project on Google Colab, following this link.\nThe program was developed during the Summer Institute in Computational Social Sciences (SICSS) 2024, hosted by FGV ECMI, Brazil, in July 2024."
  },
  {
    "objectID": "projects/machine-learning/index.html",
    "href": "projects/machine-learning/index.html",
    "title": "Machine Learning",
    "section": "",
    "text": "Nearest Neighbours Method (\\(k\\)-NN) (10/10)\nLinear Regression (8.5/10)\nLogistic Regression and Approximate Bayesian Inference (10/10)\nSelection of Models and Hyperparameters (9.25/10)\nGaussian Processes for Regression (10/10)\nNeural Networks (10/10)\nDimensionality Reduction (10/10)\nK-means and Mixture models (8.5/10)"
  },
  {
    "objectID": "projects/machine-learning/index.html#assignments",
    "href": "projects/machine-learning/index.html#assignments",
    "title": "Machine Learning",
    "section": "",
    "text": "Nearest Neighbours Method (\\(k\\)-NN) (10/10)\nLinear Regression (8.5/10)\nLogistic Regression and Approximate Bayesian Inference (10/10)\nSelection of Models and Hyperparameters (9.25/10)\nGaussian Processes for Regression (10/10)\nNeural Networks (10/10)\nDimensionality Reduction (10/10)\nK-means and Mixture models (8.5/10)"
  },
  {
    "objectID": "projects/machine-learning/index.html#final-project",
    "href": "projects/machine-learning/index.html#final-project",
    "title": "Machine Learning",
    "section": "Final Project",
    "text": "Final Project\nThe final project was co-authored by Ana Carolina Erthal, Guilherme de Melo and Bernardo Vargas. The project implements a way of comparing Conformal Prediction with traditional machine learning approaches to generate confidence intervals."
  },
  {
    "objectID": "projects/datagrid/index.html",
    "href": "projects/datagrid/index.html",
    "title": "DataGrid",
    "section": "",
    "text": "The DataGrid class is specifically designed to work with datasets that follow the structure below:\n\n\n\nColumn\nData Type\nSearch Type\nExtra\n\n\n\n\nid\ninteger\nexact\nunique\n\n\nowner_id\nstring\nexact\nExactly 5 alphanumeric characters\n\n\ncreation_date\nstring\nrange\nFormat: YYYY-MM-DD hh:mm:ss\n\n\ncount\ninteger\nrange\n\n\n\nname\nstring\ncontains\nMaximum length of 20 characters\n\n\ncontent\nstring\ncontains\n\n\n\n\nEach record in the DataGrid is considered an Event.\nTo initialize the DataGrid class, simply import the module and instantiate the class. Make sure your script can access the folder where the DataGrid module is located, for example:\nimport sys\nsys.path.append('src/')\n\nfrom datagrid import DataGrid\nInitialize the DataGrid class with:\ndatagrid = DataGrid()\nThe DataGrid class has the following methods:\n\nread_csv(file, sep = ',', encoding = 'utf-8'): populates the DataGrid from the data in the CSV file whose path is provided as a parameter, considering the specified separator and encoding;\nshow(start=0, end=100, prints = False, returns = True): displays the entries in the DataGrid, limiting the display to the range defined by the parameters. returns=True returns the list of Event objects between start and end, and prints=True shows the content of these objects. It displays the table in its current sorted state.\ninsert_row(row): inserts new events into the DataGrid. It takes a dictionary containing the data of the event to be inserted and creates an Event instance from this data. The dictionary must have the column names as keys and the data to be inserted as values, following the structure described in the table above.\ndelete_row(column, value): removes events from the DataGrid. It takes the name of the column and the value to search for in that column. It removes all events that have the searched value in the specified column. If column = 'positions', it removes elements based on their position (index) in the table. In this case, value can be either a range identified by a tuple (start, end) or a single positive integer.\nsearch(column, value): searches for events in the DataGrid. It takes the name of the column and the value to search for in that column. It returns a list of Event objects that contain the searched value in the specified column.\nsort(column, direction = 'asc'): sorts the DataGrid. It takes the name of the column and the sorting direction. To sort in descending order, simply pass direction = 'desc'.\nselect_count(i, j, how = 'median-of-medians'): returns the list of Event objects between positions i and j in the table, considering the count column sorted in ascending order. This operation does not alter the internal structure of the DataGrid. It is also possible to pass the parameter how = 'quickselect' or how = 'heapsort' to choose which algorithm will be used to perform the operation.\n\nThe file demo.ipynb contains an example of how to use the DataGrid class with data randomly generated by the file dataGenerator.py. The comments on the operations performed in the notebook refer to the results obtained using the file fake_data_100.csv, which contains 100 rows."
  },
  {
    "objectID": "projects/datagrid/index.html#user-guide",
    "href": "projects/datagrid/index.html#user-guide",
    "title": "DataGrid",
    "section": "",
    "text": "The DataGrid class is specifically designed to work with datasets that follow the structure below:\n\n\n\nColumn\nData Type\nSearch Type\nExtra\n\n\n\n\nid\ninteger\nexact\nunique\n\n\nowner_id\nstring\nexact\nExactly 5 alphanumeric characters\n\n\ncreation_date\nstring\nrange\nFormat: YYYY-MM-DD hh:mm:ss\n\n\ncount\ninteger\nrange\n\n\n\nname\nstring\ncontains\nMaximum length of 20 characters\n\n\ncontent\nstring\ncontains\n\n\n\n\nEach record in the DataGrid is considered an Event.\nTo initialize the DataGrid class, simply import the module and instantiate the class. Make sure your script can access the folder where the DataGrid module is located, for example:\nimport sys\nsys.path.append('src/')\n\nfrom datagrid import DataGrid\nInitialize the DataGrid class with:\ndatagrid = DataGrid()\nThe DataGrid class has the following methods:\n\nread_csv(file, sep = ',', encoding = 'utf-8'): populates the DataGrid from the data in the CSV file whose path is provided as a parameter, considering the specified separator and encoding;\nshow(start=0, end=100, prints = False, returns = True): displays the entries in the DataGrid, limiting the display to the range defined by the parameters. returns=True returns the list of Event objects between start and end, and prints=True shows the content of these objects. It displays the table in its current sorted state.\ninsert_row(row): inserts new events into the DataGrid. It takes a dictionary containing the data of the event to be inserted and creates an Event instance from this data. The dictionary must have the column names as keys and the data to be inserted as values, following the structure described in the table above.\ndelete_row(column, value): removes events from the DataGrid. It takes the name of the column and the value to search for in that column. It removes all events that have the searched value in the specified column. If column = 'positions', it removes elements based on their position (index) in the table. In this case, value can be either a range identified by a tuple (start, end) or a single positive integer.\nsearch(column, value): searches for events in the DataGrid. It takes the name of the column and the value to search for in that column. It returns a list of Event objects that contain the searched value in the specified column.\nsort(column, direction = 'asc'): sorts the DataGrid. It takes the name of the column and the sorting direction. To sort in descending order, simply pass direction = 'desc'.\nselect_count(i, j, how = 'median-of-medians'): returns the list of Event objects between positions i and j in the table, considering the count column sorted in ascending order. This operation does not alter the internal structure of the DataGrid. It is also possible to pass the parameter how = 'quickselect' or how = 'heapsort' to choose which algorithm will be used to perform the operation.\n\nThe file demo.ipynb contains an example of how to use the DataGrid class with data randomly generated by the file dataGenerator.py. The comments on the operations performed in the notebook refer to the results obtained using the file fake_data_100.csv, which contains 100 rows."
  },
  {
    "objectID": "projects/datagrid/index.html#random-data-generation",
    "href": "projects/datagrid/index.html#random-data-generation",
    "title": "DataGrid",
    "section": "Random Data Generation",
    "text": "Random Data Generation\nIf you want to generate random data to test the DataGrid module, simply run the file dataGenerator.py. Remember to adjust the value(s) in the n list at the end of the file to define how many files you want to generate and how many rows each should contain."
  },
  {
    "objectID": "news/news.html",
    "href": "news/news.html",
    "title": "ğŸ“°News",
    "section": "",
    "text": "February 27, 2025\nI received the Professor Carlos Eduardo Sarmento Academic Distinction Award from the School of Social Sciences at FundaÃ§Ã£o Getulio Vargas (FGV CPDOC) for achieving the highest academic performance among the 2025 graduates of the CPDOC undergraduate program! ğŸ˜ƒğŸ“\nDecember 13, 2024\nI have been accepted to pursue a Masterâ€™s degree in Applied Mathematics and Data Science at the School of Applied Mathematics (FGV EMAp). Even though Iâ€™m not accepting the offer, Iâ€™m very grateful for the opportunity and excited to continue my journey in Political Science at IESP-UERJ.\nNovember 26, 2024\nI have successfully delivered my undergraduate thesis, marking the official completion of my dual degrees in Data Science & Artificial Intelligence from the School of Applied Mathematics (FGV EMAp) and Social Sciences from the Superior School of Social Sciences (FGV CPDOC). Iâ€™m very grateful for the support of my family, friends, and advisors throughout this journey, which Iâ€™m very proud of.\nNovember 21, 2024\nI have been accepted in the first position to pursue a Masterâ€™s degree in Political Science at the Institute of Social and Political Studies (IESP-UERJ), starting in March 2025. This opportunity will allow me to contribute to impactful research, particularly in the application of Data Science and AI to the field."
  },
  {
    "objectID": "learning/learning.html",
    "href": "learning/learning.html",
    "title": "ğŸ“š Learning",
    "section": "",
    "text": "Techniques and Algorithms in Data Science\nAn introduction to some of the most important ML algorithms in Data Science â€“ regression, neural networks, decision trees, ensemble learning and unsupervised approaches.\nğŸ”— GitHub\nNumerical Linear Algebra\nNumerical methods for solving linear algebra problems.\nğŸ”— GitHub\nData Visualization\nThe fundamentals of data visualization using a variety of tools such as D3.js, Python and Power BI\nğŸ”— GitHub\nMachine Learning\nA more advanced and probabilistic approach to machine learning models, including mixture models and approximate bayesian inference.\nğŸ”— GitHub\nDeep Learning\nThe mathematical foundation of neural networks, covering topics such as CNNs, LSTMs, GANs, Transformers, Transfer Learning and deep autoencoders.\nğŸ”— GitHub\n\n\n\n\n\nLego I\nAn introduction to quantitative social sciences, covering the fundamentals of data analysis, research design, probability and inference.\nğŸ”— GitHub Â· ğŸŒ Website\nPesquisa de Survey\nThe fundamentals of survey research, including the total survey error paradigm, sampling, questionnaire design, post-stratification and topics such as non-response and likely voter models.\nğŸ”— GitHub Â· ğŸŒ Website\nTeoria PolÃ­tica I\nThe fundamental problems of political theory, from classical antiquity to the period immediately prior to the revolutions of the 18th century\nğŸ”— GitHub Â· ğŸŒ Website\n\n\n\n\n\nStudying Math\nPersonal notes and exercises from ongoing math reading.\nğŸ”— GitHub"
  },
  {
    "objectID": "learning/learning.html#repositories",
    "href": "learning/learning.html#repositories",
    "title": "ğŸ“š Learning",
    "section": "",
    "text": "Techniques and Algorithms in Data Science\nAn introduction to some of the most important ML algorithms in Data Science â€“ regression, neural networks, decision trees, ensemble learning and unsupervised approaches.\nğŸ”— GitHub\nNumerical Linear Algebra\nNumerical methods for solving linear algebra problems.\nğŸ”— GitHub\nData Visualization\nThe fundamentals of data visualization using a variety of tools such as D3.js, Python and Power BI\nğŸ”— GitHub\nMachine Learning\nA more advanced and probabilistic approach to machine learning models, including mixture models and approximate bayesian inference.\nğŸ”— GitHub\nDeep Learning\nThe mathematical foundation of neural networks, covering topics such as CNNs, LSTMs, GANs, Transformers, Transfer Learning and deep autoencoders.\nğŸ”— GitHub\n\n\n\n\n\nLego I\nAn introduction to quantitative social sciences, covering the fundamentals of data analysis, research design, probability and inference.\nğŸ”— GitHub Â· ğŸŒ Website\nPesquisa de Survey\nThe fundamentals of survey research, including the total survey error paradigm, sampling, questionnaire design, post-stratification and topics such as non-response and likely voter models.\nğŸ”— GitHub Â· ğŸŒ Website\nTeoria PolÃ­tica I\nThe fundamental problems of political theory, from classical antiquity to the period immediately prior to the revolutions of the 18th century\nğŸ”— GitHub Â· ğŸŒ Website\n\n\n\n\n\nStudying Math\nPersonal notes and exercises from ongoing math reading.\nğŸ”— GitHub"
  },
  {
    "objectID": "learning/learning.html#workshops-training",
    "href": "learning/learning.html#workshops-training",
    "title": "ğŸ“š Learning",
    "section": "ğŸ’¡ Workshops & Training",
    "text": "ğŸ’¡ Workshops & Training\n\n[July 2024] SICSS: Summer Institute in Computational Social Science\nCollaborated with international researchers on CSS projects during a two-week program at FGV.\n[July 2024] ML4Good Bootcamp\nTen-day program on AI Safety, alignment, and responsible development."
  },
  {
    "objectID": "blog/box_1976/index.html",
    "href": "blog/box_1976/index.html",
    "title": "Science and Statistics: a brief review",
    "section": "",
    "text": "In practically all disciplines across different fields of Science â€” Natural, Exact, or Social â€” one of the most fundamental discussions debated by scholars is the conceptualization of the discipline in question. In other words, it is a process of identification in order to apply. To conduct research in Statistics, one must know what Statistics is; to produce a historiographical work, one must know what History is, and so on. The task of defining a discipline, however, is not trivial, and more importantly: given a definition, it is certainly not unique, uncontested, or static. This is precisely why, over time, new methods of producing scientific knowledge are suggested and executed.\nThe article Science and Statistics (Box 1976) may, at first glance, seem like an uninteresting digression on how Ronald Fisher (1890-1962) contributed to the evolution of Statistics, in particular, and Science in general, through the methods he developed and improved. On the other hand, a more attentive reading reveals that Box (1976) actually presents his ideal view of how scientific knowledge should be produced1: â€œ[â€¦] not by mere theoretical speculation on one hand, nor by the undirected accumulation of practical facts on the other, but rather a motivated iteration between theory and practice [â€¦]â€ (Box 1976, 791).\nScientific practice, therefore, is understood by Box (1976) as a kind of loop, or a tentative theory. The researcher analyzes the available theory, makes deductions from it, and compares them to the facts â€” or data â€” that can be accessed. These two pieces of information, of distinct natures, do not necessarily converge, so the theory needs to be adjusted to explain a certain phenomenon. This new theory is compared to the facts again and so on, in a literally iterative process. The question is, therefore, the following: the confrontation between facts and theory produces errors, which imply the need to reassess one or the other element.\nThat is why â€œ[â€¦] all models are wrong [â€¦].â€ (Box 1976, 792). Naturally, all models are wrong because scientific practice results from a continuous comparison between theory and practice, so no matter how much a scientist elaborates their model in advance, it will likely need to be adapted when confronted with the factual. Box (1976), in this regard, refers to the fact that, in practice, there are no normal distributions or linearity in nature. That is, even though they are incorrect models (because they do not precisely correspond to what is found in nature), they are still useful for making approximations of what is found in the real world, as the result comes from the iteration between theory and practice. From a statisticianâ€™s point of view, the iterative process develops through a stage in which the scientist chooses the best statistical procedures to analyze the data and supports the model; in the next stage, after the analysis, they assume that the model contains errors and apply a series of residual analyses to improve it, and so on.\nThe examples based on a brief biography of Fisher serve, in practice, to illustrate the â€œbest practicesâ€ of acquiring scientific knowledge. They focus on Fisherâ€™s initial concern with solving some practical problem of scientific relevance and highlight Box (1976)â€™s ideal regarding scientific practice: one must not lose sight of the real problem to which certain statistical knowledge is being applied or even developed. Hence, the critiques of Mathematistry2, which is often disconnected from practical issues. It thus reinforces the importance of statisticians who can combine and confront theory and practice to, in fact, produce scientific knowledge."
  },
  {
    "objectID": "blog/box_1976/index.html#footnotes",
    "href": "blog/box_1976/index.html#footnotes",
    "title": "Science and Statistics: a brief review",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nIn his argument, the author addresses Science in general. Ultimately, we must keep in mind that this proposition does not necessarily encompass all scientific disciplines. Nevertheless, we know that his concern is with the Exact Sciences in general, especially Statistics.â†©ï¸\nâ€œMathematistry is characterized by development of theory for theoryâ€™s sake which since it seldom touches down with practice, has a tendency to redefine the problem rather than solve it.â€ (Box 1976, 798).â†©ï¸"
  },
  {
    "objectID": "blog/blog.html",
    "href": "blog/blog.html",
    "title": "ğŸ“¬Blog",
    "section": "",
    "text": "Science and Statistics: a brief review\n\n\n\nStatistics\n\nScience\n\n\n\nAll models are wrong; some are useful. But why is that? In this article, I review Boxâ€™s (1976) paper on the iterative process of scientific knowledge production.\n\n\n\n\n\nSep 19, 2024\n\n\nFelipe Lamarca\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Felipe Lamarca",
    "section": "",
    "text": "Welcome!ğŸ‘‹ğŸ¼\nIâ€™m a data scientist with a degree from the School of Applied Mathematics (FGV EMAp) and a social scientist with a degree from the School of Social Sciences (FGV CPDOC). Currently, Iâ€™m pursuing a Masterâ€™s degree in Political Science at the Institute of Social and Political Studies (IESP-UERJ).\nI work as a data scientist at AtlasIntel and do research at the Policy and Election Monitoring and Evaluation Laboratory (MAPE).\n\nMy interests include Statistical Modeling, Machine Learning, Deep Learning, and Computational Social Sciences. I also have experience in GenAI applications, survey methods, and ETL pipelines (SQL and NoSQL).\nğŸ“§ felipe.lamarca@hotmail.com"
  },
  {
    "objectID": "my-work/my-work.html",
    "href": "my-work/my-work.html",
    "title": "ğŸ‘¨ğŸ»â€ğŸ’» My work",
    "section": "",
    "text": "AtlasIntel provides advanced data products for political intelligence and economic forecasting.\n\n\n\nMAPE is dedicated to studying public policies, elections, and their connections. Our goal is to improve academic production on the subject and to have a decisive impact on public debate. In particular, we combine different methodologies to study policies and elections, including causal inference techniques and machine learning.\nIf you think I can help you in any way, please reach out at felipe.lamarca@hotmail.com."
  },
  {
    "objectID": "my-work/my-work.html#current-roles",
    "href": "my-work/my-work.html#current-roles",
    "title": "ğŸ‘¨ğŸ»â€ğŸ’» My work",
    "section": "",
    "text": "AtlasIntel provides advanced data products for political intelligence and economic forecasting.\n\n\n\nMAPE is dedicated to studying public policies, elections, and their connections. Our goal is to improve academic production on the subject and to have a decisive impact on public debate. In particular, we combine different methodologies to study policies and elections, including causal inference techniques and machine learning.\nIf you think I can help you in any way, please reach out at felipe.lamarca@hotmail.com."
  },
  {
    "objectID": "my-work/my-work.html#past-work",
    "href": "my-work/my-work.html#past-work",
    "title": "ğŸ‘¨ğŸ»â€ğŸ’» My work",
    "section": "ğŸ“ Past Work",
    "text": "ğŸ“ Past Work\n\nğŸ“ Consultant in Data Science & Research (07/2024 â€“ 06/2025)\nProvided end-to-end data and AI solutions (ETL, ML, Generative AI, RAG), research support, and training.\nSelected consulting projects:\n\nğŸ“Œ Artplan: Deep Learning for social media segmentation\nğŸ“Œ FundaÃ§Ã£o Roberto Marinho: AWS data lake, dashboards (Streamlit and Power BI), Python/ML training\nğŸ“Œ CEBRAP: OCR, LLMs, and quantitative research support for Prof.Â JosÃ© Szwako\nğŸ“Œ Plataforma CIPÃ“: Training in ML and data analysis\nğŸ“Œ GENI/UFF: Built LLM and RAG-based data tools\n\n\n\nğŸ“ Data Scientist & Researcher @ Instituto Rio21 (04/2022 â€“ 06/2025)\nI conducted quantitative research such as opinion polls and other surveys such as the [Municipal Management Assessment Survey] and [Election Polls]. I also collaborated with AlianÃ§a CentroRio to transform citywide conservation and security data into actionable intelligence.\n\n\nğŸ“ Research Assistant @ FGV EBAPE (02/2025 â€“ 04/2025)\nI worked on a project to systematize databases for election results from the 1970s, using OCR and large language models to digitize and format historical documents. I worked under the supervision of Prof.Â Cesar Zucco, Ph.D.\n\n\n\nğŸ“ Data Science Intern @ Strategic Planning Superintendence, FGV (10/2024 â€“ 12/2024)\nI integrated advanced Generative AI techniques into institutional data pipelines, identifying opportunities for automation and process improvement. I also prepared presentations for C-level executives, including the President of FGV.\n\n\nğŸ“ Part-time Data Scientist @ Visagio (01/2024 â€“ 06/2024)\nI worked on optimization, pricing, A/B testing, and data pipeline automation with SQL. I developed Power BI dashboards and presented KPI-driven insights to senior management.\n\n\nğŸ“ Student Consultant @ Brazilian Sailing Confederation (08/2023 â€“ 12/2023)\nI collaborated with colleagues to develop a ranking model for Brazilian sailors, integrating web scraping and machine learning to analyze regatta performance.\n\n\nğŸ“ Junior Research Fellow @ FGV CPDOC (06/2019 â€“ 09/2022)\nSupported by an FGV/CNPq scholarship under the supervision of Prof.Â Jaqueline Porto Zulini, Ph.D., I examined Executive-Legislative relations in the early 20th century, applying both qualitative methods and introductory quantitative text analysis."
  },
  {
    "objectID": "my-work/my-work.html#teaching-assistance",
    "href": "my-work/my-work.html#teaching-assistance",
    "title": "ğŸ‘¨ğŸ»â€ğŸ’» My work",
    "section": "ğŸ“š Teaching Assistance",
    "text": "ğŸ“š Teaching Assistance\n\n\n\nSemester\nCourse\nInstitution\nProfessor\n\n\n\n\n2024.2\nQuantitative Methods II\nFGV CPDOC\nJairo Nicolau, Ph.D.\n\n\n2020.2\nIntroduction to R\nFGV CPDOC\nJimmy Medeiros, Ph.D.\n\n\n\n(Previously, I also worked on â€œDigital Literacyâ€ projects and translated materials for the Programming Historian in Portuguese in partnership with Universidade Nova de Lisboa.)"
  },
  {
    "objectID": "my-work/my-work.html#references",
    "href": "my-work/my-work.html#references",
    "title": "ğŸ‘¨ğŸ»â€ğŸ’» My work",
    "section": "ğŸ“ References",
    "text": "ğŸ“ References\n\n\n\n\n\n\n\n\nName\nInstitution\nEmail\n\n\n\n\nProf.Â Jaqueline Zulini, PhD\nSchool of Social Sciences (FGV CPDOC)\njaqueline dot zulini at fgv dot br\n\n\nProf.Â Luiz Max Carvalho, PhD\nSchool of Applied Mathematics (FGV EMAp)\nluiz dot fagundes at fgv dot br\n\n\nProf.Â Renato Rocha Souza, PhD\nUniversity of Vienna\nrenato dot rocha dot souza at univie dot ac dot at\n\n\nProf.Â Danielle Sanches, PhD\nSchool of Communication, Media and Information (FGV ECMI)\ndanielle dot sanches at fgv dot br\n\n\nProf.Â Jimmy Medeiros, PhD\nSchool of Social Sciences (FGV CPDOC)\njimmy dot medeiros at fgv dot br"
  },
  {
    "objectID": "projects/data-visualization/index.html",
    "href": "projects/data-visualization/index.html",
    "title": "Data Visualization",
    "section": "",
    "text": "Sketch of Visualizations\nVisualization Project\nExploratory Data Analysis"
  },
  {
    "objectID": "projects/data-visualization/index.html#assignments",
    "href": "projects/data-visualization/index.html#assignments",
    "title": "Data Visualization",
    "section": "",
    "text": "Sketch of Visualizations\nVisualization Project\nExploratory Data Analysis"
  },
  {
    "objectID": "projects/data-visualization/index.html#projects",
    "href": "projects/data-visualization/index.html#projects",
    "title": "Data Visualization",
    "section": "Projects",
    "text": "Projects\n\nProject 1: VocÃª em Dados\nProject co-developed with Ana Carolina Erthal and Guilherme de Melo.\nSee the project here.\n\n\nProject 2: Visual F1\nProject co-developed with Ana Carolina Erthal and Guilherme de Melo.\nSee the project here."
  },
  {
    "objectID": "projects/deep-learning/index.html",
    "href": "projects/deep-learning/index.html",
    "title": "Deep Learning",
    "section": "",
    "text": "Assignment 1: Transfer Learning (10/10)\nAssignment 2: Semantic Segmentation (10/10)\nAssignment 3: Action Recognition (10/10)\nAssignment 4: Generative Adversarial Networks + Autoencoders (10/10)\nAssignment 5: Deep \\(k\\)-Means (10/10)\nPresentation: YUN, S. et al.Â Graph Transformer Networks. In: NeurIPS, 2019. [pdf] [slides]\nAll notebooks were ran on Google Colab.\nThe repository also contains the cheatsheets folder with some useful concepts of Deep Learning I have written down during the course.\n\n\n\nCitationBibTeX citation:@online{lamarca2023,\n  author = {Lamarca, Felipe and Carolina Erthal, Ana},\n  title = {Deep {Learning}},\n  date = {2023-12-05},\n  url = {https://github.com/felipelmc/Deep-Learning},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nLamarca, Felipe, and Ana Carolina Erthal. 2023. â€œDeep\nLearning.â€ December 5, 2023. https://github.com/felipelmc/Deep-Learning."
  },
  {
    "objectID": "projects/projects.html",
    "href": "projects/projects.html",
    "title": "âš™Projects",
    "section": "",
    "text": "SciELO-Summarizer\n\n\n\nComputational Social Sciences\n\nDeep Learning\n\n\n\nSciELO-Summarizer consists of a summarizer for scientific articles in Portuguese. It scrapes the content of the article from the SciELO website and generates a personalized summary for the user using Large Language Models (LLMs), especifically Llama3.\n\n\n\n\n\nJul 15, 2024\n\n\nFelipe Lamarca, Claudia Fernandes, Daniel Zacarias, Gabriellen Carmo, Lauriano Benazzi, Marcelle Amaral, Talita Ribeiro\n\n\n\n\n\n\n\n\n\n\n\n\nDeep Learning\n\n\n\nDeep Learning\n\n\n\nAssignments and presentation developed in the scope of the Deep Learning discipline, taught by Professor DÃ¡rio Oliveira (FGV EMAp). Co-authored with @anacarolerthal, whom I thank for the ongoing partnership.\n\n\n\n\n\nDec 5, 2023\n\n\nFelipe Lamarca, Ana Carolina Erthal\n\n\n\n\n\n\n\n\n\n\n\n\nDataGrid\n\n\n\nAlgorithms\n\n\n\nImplementation of search, sorting & selection algorithms to build an efficient datagrid. Project developed within the scope of the Algorithm Design and Analysis discipline, lectured by Professor Thiago Pinheiro de AraÃºjo (FGV EMAp).\n\n\n\n\n\nOct 18, 2023\n\n\nFelipe Lamarca, Cristiano LarrÃ©a\n\n\n\n\n\n\n\n\n\n\n\n\nStatistical Modeling\n\n\n\nStatistics\n\nComputational Social Sciences\n\n\n\nThis repository gathers the data, scripts, and analyses conducted for the final project of the Statistical Modeling course, taught by Professor Luiz Max Fagundes de Carvalho (FGV EMAp) (@maxbiostat). The objective was to apply modeling, inference, and prediction techniques, learned throughout this course and the Statistical Inference course, to real-world data.\n\n\n\n\n\nJul 15, 2023\n\n\nFelipe Lamarca\n\n\n\n\n\n\n\n\n\n\n\n\nMachine Learning\n\n\n\nMachine Learning\n\nStatistics\n\n\n\nThis repository contains all the assignments and the project I did for the Machine Learning course at the School of Applied Mathematics of the Getulio Vargas Foundation (FGV EMAp). The course was taught by Professor Diego Mesquita.\n\n\n\n\n\nJul 5, 2023\n\n\nFelipe Lamarca\n\n\n\n\n\n\n\n\n\n\n\n\nData Visualization\n\n\n\nData Visualization\n\n\n\nRepository where I keep all the assignments and projects developed in the scope of the Data Visualization discipline, taught by Professor Jorge Poco (@jpocom) (FGV EMAp).\n\n\n\n\n\nJun 30, 2023\n\n\nFelipe Lamarca, Ana Carolina Erthal, Guilherme de Melo\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "projects/statistical-modeling/index.html",
    "href": "projects/statistical-modeling/index.html",
    "title": "Statistical Modeling",
    "section": "",
    "text": "I chose to analyze the electoral dynamics for the position of federal deputy in the 2022 elections. Specifically, I explore multilevel (hierarchical) models, logistic regression, and model evaluation methods, such as AUC, AIC, accuracy, and \\(R^2\\). Additionally, I engage with part of the Political Science literature that uses Statistical Modeling techniques to extract information about Brazilian elections.\nThis work resulted in this report, the summary of which is as follows:"
  },
  {
    "objectID": "projects/statistical-modeling/index.html#about-the-project",
    "href": "projects/statistical-modeling/index.html#about-the-project",
    "title": "Statistical Modeling",
    "section": "",
    "text": "I chose to analyze the electoral dynamics for the position of federal deputy in the 2022 elections. Specifically, I explore multilevel (hierarchical) models, logistic regression, and model evaluation methods, such as AUC, AIC, accuracy, and \\(R^2\\). Additionally, I engage with part of the Political Science literature that uses Statistical Modeling techniques to extract information about Brazilian elections.\nThis work resulted in this report, the summary of which is as follows:"
  },
  {
    "objectID": "projects/statistical-modeling/index.html#who-wants-to-be-a-deputy-a-multilevel-analysis-of-the-2022-elections-for-the-chamber-of-deputies",
    "href": "projects/statistical-modeling/index.html#who-wants-to-be-a-deputy-a-multilevel-analysis-of-the-2022-elections-for-the-chamber-of-deputies",
    "title": "Statistical Modeling",
    "section": "Who Wants to Be a Deputy? A Multilevel Analysis of the 2022 Elections for the Chamber of Deputies",
    "text": "Who Wants to Be a Deputy? A Multilevel Analysis of the 2022 Elections for the Chamber of Deputies\nWhat increases a candidateâ€™s chances of being elected? The specialized Political Science literature has sought to answer this question through various approaches over time. This work provides a statistical analysis of the 2022 electoral data to evaluate what impacts the chances of federal deputy candidates being elected in Brazil. Statistical modeling techniques are applied, including multilevel logistic regression models and metrics for evaluating the explanatory and predictive capacity of models. The results suggest that campaign expenditures, with variations between parties, account for a significant portion of the results at the polls.\nKeywords: Legislative Elections; Logistic Regression; Multilevel Models; Model Evaluation.\nThe work has been completed and received the highest grade."
  }
]