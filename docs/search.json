[
  {
    "objectID": "publications/publications.html",
    "href": "publications/publications.html",
    "title": "‚úçüèºPublications",
    "section": "",
    "text": "F. Lamarca, ‚ÄúAs rela√ß√µes Executivo-Legislativo na Primeira Rep√∫blica: uma an√°lise das mensagens presidenciais ao Congresso (1910-1920)‚Äù, Mosaico, vol.¬†13, no. 20, pp.¬†525-546, 2021. [link] [pdf]"
  },
  {
    "objectID": "publications/publications.html#papers",
    "href": "publications/publications.html#papers",
    "title": "‚úçüèºPublications",
    "section": "",
    "text": "F. Lamarca, ‚ÄúAs rela√ß√µes Executivo-Legislativo na Primeira Rep√∫blica: uma an√°lise das mensagens presidenciais ao Congresso (1910-1920)‚Äù, Mosaico, vol.¬†13, no. 20, pp.¬†525-546, 2021. [link] [pdf]"
  },
  {
    "objectID": "publications/publications.html#translations",
    "href": "publications/publications.html#translations",
    "title": "‚úçüèºPublications",
    "section": "Translations",
    "text": "Translations\nJ. Baker and I. Milligan, ‚ÄúContagem e minera√ß√£o de dados de investiga√ß√£o com Unix,‚Äù translated by F. Lamarca, Programming Historian em portugu√™s, Dec.¬†2021. [link]\nF. Gibbs, ‚ÄúInstala√ß√£o de M√≥dulos Python com pip,‚Äù translated by F. Lamarca, Programming Historian em portugu√™s, Dec.¬†2021. [link]\nW. Turkel and A. Crymble, ‚ÄúReutiliza√ß√£o de c√≥digo e modularidade em Python,‚Äù translated by F. Lamarca, Programming Historian em portugu√™s, May 2021. [link]\nW. Turkel and A. Crymble, ‚ÄúContagem de Frequ√™ncias de Palavras com Python,‚Äù translated by F. Lamarca, Programming Historian em portugu√™s, Jan.¬†2022. [link]\nW. Turkel and A. Crymble, ‚ÄúDe HTML para Lista de Palavras (parte 1),‚Äù translated by F. Lamarca, Programming Historian em portugu√™s, Oct.¬†2022. [link]\nW. Turkel and A. Crymble, ‚ÄúNormaliza√ß√£o de Dados Textuais com Python,‚Äù translated by F. Lamarca, Programming Historian em portugu√™s, Oct.¬†2022. [link]\nW. Turkel and A. Crymble, ‚ÄúCria√ß√£o e Visualiza√ß√£o de Ficheiros HTML com Python,‚Äù translated by F. Lamarca, Programming Historian em portugu√™s, Oct.¬†2022. [link]\nW. Turkel and A. Crymble, ‚ÄúPalavras-chave em Contexto (usando n-grams) com Python,‚Äù translated by F. Lamarca, Programming Historian em portugu√™s, Oct.¬†2022. [link]\nW. Turkel and A. Crymble, ‚ÄúSa√≠da de Dados como um ficheiro HTML com Python,‚Äù translated by F. Lamarca, Programming Historian em portugu√™s, Oct.¬†2022. [link]\nA. Crymble, ‚ÄúDownload de M√∫ltiplos Registros usando Query Strings,‚Äù translated by F. Lamarca, Programming Historian em portugu√™s, Nov.¬†2022. [link]\nW. Turkel and A. Crymble, ‚ÄúDe HTML para Lista de Palavras (parte 2),‚Äù translated by F. Lamarca, Programming Historian em portugu√™s, Dec.¬†2022. [link]"
  },
  {
    "objectID": "projects/scielo-summarizer/index.html",
    "href": "projects/scielo-summarizer/index.html",
    "title": "SciELO-Summarizer",
    "section": "",
    "text": "SciELO-Summarizer consists of a summarizer for scientific articles in Portuguese. It scrapes the content of the article from the SciELO website and generates a personalized summary for the user using Large Language Models (LLMs), especifically Llama3.\nTo run the project locally, you need to have both Python 3.8 or higher and Llama3 installed. It is also possible to run the project on Google Colab, following this link.\nThe program was developed during the Summer Institute in Computational Social Sciences (SICSS) 2024, hosted by FGV ECMI, Brazil, in July 2024."
  },
  {
    "objectID": "projects/scielo-summarizer/index.html#about-the-project",
    "href": "projects/scielo-summarizer/index.html#about-the-project",
    "title": "SciELO-Summarizer",
    "section": "",
    "text": "SciELO-Summarizer consists of a summarizer for scientific articles in Portuguese. It scrapes the content of the article from the SciELO website and generates a personalized summary for the user using Large Language Models (LLMs), especifically Llama3.\nTo run the project locally, you need to have both Python 3.8 or higher and Llama3 installed. It is also possible to run the project on Google Colab, following this link.\nThe program was developed during the Summer Institute in Computational Social Sciences (SICSS) 2024, hosted by FGV ECMI, Brazil, in July 2024."
  },
  {
    "objectID": "projects/machine-learning/index.html",
    "href": "projects/machine-learning/index.html",
    "title": "Machine Learning",
    "section": "",
    "text": "Nearest Neighbours Method (\\(k\\)-NN) (10/10)\nLinear Regression (8.5/10)\nLogistic Regression and Approximate Bayesian Inference (10/10)\nSelection of Models and Hyperparameters (9.25/10)\nGaussian Processes for Regression (10/10)\nNeural Networks (10/10)\nDimensionality Reduction (10/10)\nK-means and Mixture models (8.5/10)"
  },
  {
    "objectID": "projects/machine-learning/index.html#assignments",
    "href": "projects/machine-learning/index.html#assignments",
    "title": "Machine Learning",
    "section": "",
    "text": "Nearest Neighbours Method (\\(k\\)-NN) (10/10)\nLinear Regression (8.5/10)\nLogistic Regression and Approximate Bayesian Inference (10/10)\nSelection of Models and Hyperparameters (9.25/10)\nGaussian Processes for Regression (10/10)\nNeural Networks (10/10)\nDimensionality Reduction (10/10)\nK-means and Mixture models (8.5/10)"
  },
  {
    "objectID": "projects/machine-learning/index.html#final-project",
    "href": "projects/machine-learning/index.html#final-project",
    "title": "Machine Learning",
    "section": "Final Project",
    "text": "Final Project\nThe final project was co-authored by Ana Carolina Erthal, Guilherme de Melo and Bernardo Vargas. The project implements a way of comparing Conformal Prediction with traditional machine learning approaches to generate confidence intervals."
  },
  {
    "objectID": "projects/datagrid/index.html",
    "href": "projects/datagrid/index.html",
    "title": "DataGrid",
    "section": "",
    "text": "The DataGrid class is specifically designed to work with datasets that follow the structure below:\n\n\n\nColumn\nData Type\nSearch Type\nExtra\n\n\n\n\nid\ninteger\nexact\nunique\n\n\nowner_id\nstring\nexact\nExactly 5 alphanumeric characters\n\n\ncreation_date\nstring\nrange\nFormat: YYYY-MM-DD hh:mm:ss\n\n\ncount\ninteger\nrange\n\n\n\nname\nstring\ncontains\nMaximum length of 20 characters\n\n\ncontent\nstring\ncontains\n\n\n\n\nEach record in the DataGrid is considered an Event.\nTo initialize the DataGrid class, simply import the module and instantiate the class. Make sure your script can access the folder where the DataGrid module is located, for example:\nimport sys\nsys.path.append('src/')\n\nfrom datagrid import DataGrid\nInitialize the DataGrid class with:\ndatagrid = DataGrid()\nThe DataGrid class has the following methods:\n\nread_csv(file, sep = ',', encoding = 'utf-8'): populates the DataGrid from the data in the CSV file whose path is provided as a parameter, considering the specified separator and encoding;\nshow(start=0, end=100, prints = False, returns = True): displays the entries in the DataGrid, limiting the display to the range defined by the parameters. returns=True returns the list of Event objects between start and end, and prints=True shows the content of these objects. It displays the table in its current sorted state.\ninsert_row(row): inserts new events into the DataGrid. It takes a dictionary containing the data of the event to be inserted and creates an Event instance from this data. The dictionary must have the column names as keys and the data to be inserted as values, following the structure described in the table above.\ndelete_row(column, value): removes events from the DataGrid. It takes the name of the column and the value to search for in that column. It removes all events that have the searched value in the specified column. If column = 'positions', it removes elements based on their position (index) in the table. In this case, value can be either a range identified by a tuple (start, end) or a single positive integer.\nsearch(column, value): searches for events in the DataGrid. It takes the name of the column and the value to search for in that column. It returns a list of Event objects that contain the searched value in the specified column.\nsort(column, direction = 'asc'): sorts the DataGrid. It takes the name of the column and the sorting direction. To sort in descending order, simply pass direction = 'desc'.\nselect_count(i, j, how = 'median-of-medians'): returns the list of Event objects between positions i and j in the table, considering the count column sorted in ascending order. This operation does not alter the internal structure of the DataGrid. It is also possible to pass the parameter how = 'quickselect' or how = 'heapsort' to choose which algorithm will be used to perform the operation.\n\nThe file demo.ipynb contains an example of how to use the DataGrid class with data randomly generated by the file dataGenerator.py. The comments on the operations performed in the notebook refer to the results obtained using the file fake_data_100.csv, which contains 100 rows."
  },
  {
    "objectID": "projects/datagrid/index.html#user-guide",
    "href": "projects/datagrid/index.html#user-guide",
    "title": "DataGrid",
    "section": "",
    "text": "The DataGrid class is specifically designed to work with datasets that follow the structure below:\n\n\n\nColumn\nData Type\nSearch Type\nExtra\n\n\n\n\nid\ninteger\nexact\nunique\n\n\nowner_id\nstring\nexact\nExactly 5 alphanumeric characters\n\n\ncreation_date\nstring\nrange\nFormat: YYYY-MM-DD hh:mm:ss\n\n\ncount\ninteger\nrange\n\n\n\nname\nstring\ncontains\nMaximum length of 20 characters\n\n\ncontent\nstring\ncontains\n\n\n\n\nEach record in the DataGrid is considered an Event.\nTo initialize the DataGrid class, simply import the module and instantiate the class. Make sure your script can access the folder where the DataGrid module is located, for example:\nimport sys\nsys.path.append('src/')\n\nfrom datagrid import DataGrid\nInitialize the DataGrid class with:\ndatagrid = DataGrid()\nThe DataGrid class has the following methods:\n\nread_csv(file, sep = ',', encoding = 'utf-8'): populates the DataGrid from the data in the CSV file whose path is provided as a parameter, considering the specified separator and encoding;\nshow(start=0, end=100, prints = False, returns = True): displays the entries in the DataGrid, limiting the display to the range defined by the parameters. returns=True returns the list of Event objects between start and end, and prints=True shows the content of these objects. It displays the table in its current sorted state.\ninsert_row(row): inserts new events into the DataGrid. It takes a dictionary containing the data of the event to be inserted and creates an Event instance from this data. The dictionary must have the column names as keys and the data to be inserted as values, following the structure described in the table above.\ndelete_row(column, value): removes events from the DataGrid. It takes the name of the column and the value to search for in that column. It removes all events that have the searched value in the specified column. If column = 'positions', it removes elements based on their position (index) in the table. In this case, value can be either a range identified by a tuple (start, end) or a single positive integer.\nsearch(column, value): searches for events in the DataGrid. It takes the name of the column and the value to search for in that column. It returns a list of Event objects that contain the searched value in the specified column.\nsort(column, direction = 'asc'): sorts the DataGrid. It takes the name of the column and the sorting direction. To sort in descending order, simply pass direction = 'desc'.\nselect_count(i, j, how = 'median-of-medians'): returns the list of Event objects between positions i and j in the table, considering the count column sorted in ascending order. This operation does not alter the internal structure of the DataGrid. It is also possible to pass the parameter how = 'quickselect' or how = 'heapsort' to choose which algorithm will be used to perform the operation.\n\nThe file demo.ipynb contains an example of how to use the DataGrid class with data randomly generated by the file dataGenerator.py. The comments on the operations performed in the notebook refer to the results obtained using the file fake_data_100.csv, which contains 100 rows."
  },
  {
    "objectID": "projects/datagrid/index.html#random-data-generation",
    "href": "projects/datagrid/index.html#random-data-generation",
    "title": "DataGrid",
    "section": "Random Data Generation",
    "text": "Random Data Generation\nIf you want to generate random data to test the DataGrid module, simply run the file dataGenerator.py. Remember to adjust the value(s) in the n list at the end of the file to define how many files you want to generate and how many rows each should contain."
  },
  {
    "objectID": "posts/posts.html",
    "href": "posts/posts.html",
    "title": "üì¨Posts",
    "section": "",
    "text": "Science and Statistics: a brief review\n\n\n\n\n\n\nStatistics\n\n\nScience\n\n\n\nAll models are wrong; some are useful. But why is that? In this article, I review Box‚Äôs (1976) paper on the iterative process of scientific knowledge production. \n\n\n\n\n\nSep 19, 2024\n\n\nFelipe Lamarca\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "news/news.html",
    "href": "news/news.html",
    "title": "üì∞News",
    "section": "",
    "text": "November 26, 2024\nI have successfully delivered my undergraduate thesis, marking the official completion of my dual degrees in Data Science & Artificial Intelligence from the School of Applied Mathematics (FGV EMAp) and Social Sciences from the Superior School of Social Sciences (FGV CPDOC). I‚Äôm very grateful for the support of my family, friends, and advisors throughout this journey, which I‚Äôm very proud of.\nNovember 21, 2024\nI have been accepted in the first position to pursue a Master‚Äôs degree in Political Science at the Institute of Social and Political Studies (IESP-UERJ), starting in March 2025. This opportunity will allow me to contribute to impactful research, particularly in the application of Data Science and AI to the field.\nAugust 06, 2024\nI‚Äôve been accepted into the AI Safety Fundamentals: Governance course, offered by BlueDot Impact. I look forward to deepening my understanding of AI Governance, connecting with others in the field, and contributing to impactful work in AI Safety.\nAugust 01, 2024\nI‚Äôve started a new role as a Teaching Assistant for Quantitative Methods II, under the supervision of Professor Jairo Nicolau, PhD. My goal is to help students from the Social Sciences to learn useful skills for industry, academia, and government, such as programming and statistics.\nJune 18, 2024\nThe research project of my undergraduate thesis, titled The determinants of electoral success in legislative elections in Brazil: an approach using Bayesian multilevel models, was approved with full marks. I am deeply grateful to Professors Jaqueline Zulini, PhD and Luiz Max Carvalho, PhD for their outstanding supervision. I‚Äôm excited to dive deep into this research!\nJune 18, 2024\nI have been accepted to participate in the Summer Institute in Computational Social Sciences, hosted by FGV ECMI, in July 2024. It‚Äôs an intensive two-week program that offers training in CSS techniques useful for academia, industry, and government.\nJune 11, 2024\nI have been accepted to participate in the next edition of ML4Good, in S√£o Paulo, Brazil, in July 2024. It‚Äôs a ten-day bootcamp that promotes upskilling in Deep Learning and AI Safety topics."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Felipe Lamarca",
    "section": "",
    "text": "Welcome!üëãüèº\nI am a data scientist from the School of Applied Mathematics (FGV EMAp) and a social scientist from the Superior School of Social Sciences (FGV CPDOC). My academic background combines a strong foundation in mathematics, programming, and social sciences, with a focus on political science and computational social sciences. I apply this interdisciplinary expertise to tackle complex challenges in both the public and private sectors while contributing to the advancement of scientific knowledge.\nI‚Äôm mainly interested in the following topics:\n\nStatistics, Machine Learning, and Deep Learning\nComputational Social Sciences, Political Science, and Public Policy\nAI Safety and Governance\nOpen source tools and reproducible research\n\nüìß felipe.lamarca@hotmail.com\n\n\nFun Facts\n\nI‚Äôm a proud Carioca üå¥üåäüåû. Born and raised in Rio de Janeiro, Brazil üáßüá∑\nEnjoy playing video gamesüéÆ and (occasionally) exercisingüèÉüèª"
  },
  {
    "objectID": "my-work/my-work.html",
    "href": "my-work/my-work.html",
    "title": "üë®üèª‚ÄçüíªMy work",
    "section": "",
    "text": "I help clients solve data-related problems, engaging in a wide range of projects. I have experience working on all stages of the data science pipeline, from the implementation of ETL pipelines to the development and integration of machine learning models, including GenAI applications. I also provide research support, such as data collection, analysis, and visualization.\nCurrent and past clients include NGOs, companies, public officials, politicians, and researchers from Brazilian think tanks and universities. If you think I can help you in any way, please reach out to me at felipe.lamarca@hotmail.com.\nYou can also explore my open-source projects here or on GitHub profile.\n\n\n\nI have been working at Instituto Rio21 since 2022, focusing on data collection, analysis, and visualization, with a special emphasis on opinion polls and social surveys. I have been involved in projects such as the Municipal Management Assessment Survey and Election Polls, while also working closely with Alian√ßa CentroRio to improve city life by turning data on conservation and security into intelligence.\nIn a daily basis, I use tools such as Python, R, SQL, and PowerBI to perform geo-referencing, interactive maps, dashboards, and statistical analysis.\n\n\n\nThe institutional goal of the Getulio Vargas Foundation is to estimulate the social and economic development of Brazil. The role of the Strategic Planning and Management Office (SPE) is to support FGV‚Äôs units in achieving institutional goals through KPI monitoring and fostering a data-driven culture.\nI have been working mainly on incorporating advanced GenAI techniques into the area‚Äôs data pipeline and identifying opportunities for automation and process improvement. I also support the development of presentations for C-level executives."
  },
  {
    "objectID": "my-work/my-work.html#current-work",
    "href": "my-work/my-work.html#current-work",
    "title": "üë®üèª‚ÄçüíªMy work",
    "section": "",
    "text": "Data Scientist & Researcher @ Instituto Rio21 - Scope: Data collection, analysis, and visualization, focusing on opinion polls and social surveys. - Highlighted Projects: Municipal Management Assessment Survey and Election Polls - Project Partner: Alian√ßa CentroRio, improving city life through data on conservation and security - Technical Skills: Geo-referencing, interactive maps, dashboards, statistical analysis.\nI am a Data Scientist and Researcher at Instituto Rio21. Here, I work on projects related data collection, analysis, and visualization. I also conduct opinion polls and surveys such as the Municipal Management Assessment Survey and Election Polls using post-stratification techniques. We provide services to the project Alian√ßa CentroRio, which aims to improve the quality of life in the downtown area of Rio de Janeiro by monitoring the city hall performance in services related to conservation and security. My work involves geo-referencing data, creating interactive maps and dashboards, and conducting statistical analysis.\nI also work as a freelance consultant, offering expertise in data and social sciences to Brazilian politicians, NGOs, companies, and researchers. Companies and think tanks I have worked with include Funda√ß√£o Roberto Marinho, Artplan, Instituto Vini.Jr, FGV, and CEBRAP. The scope of my work ranges from data analysis and business intelligence to social science research and policy analysis. I use a variety of tools and methods, such as Python, R, SQL, Statistics, Machine Learning, and Deep Learning.\nYou can also see some of my open-source projects here."
  },
  {
    "objectID": "my-work/my-work.html#teaching-assistance",
    "href": "my-work/my-work.html#teaching-assistance",
    "title": "üë®üèª‚ÄçüíªMy work",
    "section": "Teaching Assistance",
    "text": "Teaching Assistance\n\n[2024.2] Quantitative Methods II (FGV CPDOC), Professor Jairo Nicolau, Ph.D.\n[2020.2] Introduction to R (FGV CPDOC), Professor Jimmy Medeiros, Ph.D."
  },
  {
    "objectID": "my-work/my-work.html#training-and-workshops-attended",
    "href": "my-work/my-work.html#training-and-workshops-attended",
    "title": "üë®üèª‚ÄçüíªMy work",
    "section": "Training and Workshops attended",
    "text": "Training and Workshops attended\n\n[July 2024] Summer Institute in Computational Social Sciences, FGV ECMI\n[July 2024] ML4Good, Centre pour la S√©curit√© de l‚ÄôIA (CeSIA) and EffiSciences"
  },
  {
    "objectID": "my-work/my-work.html#past-work",
    "href": "my-work/my-work.html#past-work",
    "title": "üë®üèª‚ÄçüíªMy work",
    "section": "üëî Past Work",
    "text": "üëî Past Work\n\nData Scientist @ Visagio\nAs a part-time data scientist at Visagio, I worked on a variety of projects, including optimization, pricing, A/B testing, and Power BI dashboard development. I led the automation of the data pipeline using SQL and presented KPI-driven insights to senior management.\n\n\nStudent Consultant @ Brazilian Sailing Confederation\nWith the help of some friends, I developed a ranking model for Brazilian sailors, integrating web scraping and machine learning to analyze regatta performance.\n\n\nJunior Research Fellow @ FGV CPDOC\nUnder the supervision of Prof.¬†Jaqueline Porto Zulini, Ph.D., I analyzed Executive-Legislative relations (1900-1930) qualitatively, and a little bit quantitatively, using R. This was my very first experience with quantitative text analysis, even though it was not the main focus of the project.\n\n\nResearcher @ FGV\nUnder the supervision of Prof.¬†Jimmy Medeiros, Ph.D., I translated and adapted tutorials for the Programming Historian in Portuguese."
  },
  {
    "objectID": "posts/box_1976/index.html",
    "href": "posts/box_1976/index.html",
    "title": "Science and Statistics: a brief review",
    "section": "",
    "text": "In practically all disciplines across different fields of Science ‚Äî Natural, Exact, or Social ‚Äî one of the most fundamental discussions debated by scholars is the conceptualization of the discipline in question. In other words, it is a process of identification in order to apply. To conduct research in Statistics, one must know what Statistics is; to produce a historiographical work, one must know what History is, and so on. The task of defining a discipline, however, is not trivial, and more importantly: given a definition, it is certainly not unique, uncontested, or static. This is precisely why, over time, new methods of producing scientific knowledge are suggested and executed.\nThe article Science and Statistics (Box 1976) may, at first glance, seem like an uninteresting digression on how Ronald Fisher (1890-1962) contributed to the evolution of Statistics, in particular, and Science in general, through the methods he developed and improved. On the other hand, a more attentive reading reveals that Box (1976) actually presents his ideal view of how scientific knowledge should be produced1: ‚Äú[‚Ä¶] not by mere theoretical speculation on one hand, nor by the undirected accumulation of practical facts on the other, but rather a motivated iteration between theory and practice [‚Ä¶]‚Äù (Box 1976, 791).\nScientific practice, therefore, is understood by Box (1976) as a kind of loop, or a tentative theory. The researcher analyzes the available theory, makes deductions from it, and compares them to the facts ‚Äî or data ‚Äî that can be accessed. These two pieces of information, of distinct natures, do not necessarily converge, so the theory needs to be adjusted to explain a certain phenomenon. This new theory is compared to the facts again and so on, in a literally iterative process. The question is, therefore, the following: the confrontation between facts and theory produces errors, which imply the need to reassess one or the other element.\nThat is why ‚Äú[‚Ä¶] all models are wrong [‚Ä¶].‚Äù (Box 1976, 792). Naturally, all models are wrong because scientific practice results from a continuous comparison between theory and practice, so no matter how much a scientist elaborates their model in advance, it will likely need to be adapted when confronted with the factual. Box (1976), in this regard, refers to the fact that, in practice, there are no normal distributions or linearity in nature. That is, even though they are incorrect models (because they do not precisely correspond to what is found in nature), they are still useful for making approximations of what is found in the real world, as the result comes from the iteration between theory and practice. From a statistician‚Äôs point of view, the iterative process develops through a stage in which the scientist chooses the best statistical procedures to analyze the data and supports the model; in the next stage, after the analysis, they assume that the model contains errors and apply a series of residual analyses to improve it, and so on.\nThe examples based on a brief biography of Fisher serve, in practice, to illustrate the ‚Äúbest practices‚Äù of acquiring scientific knowledge. They focus on Fisher‚Äôs initial concern with solving some practical problem of scientific relevance and highlight Box (1976)‚Äôs ideal regarding scientific practice: one must not lose sight of the real problem to which certain statistical knowledge is being applied or even developed. Hence, the critiques of Mathematistry2, which is often disconnected from practical issues. It thus reinforces the importance of statisticians who can combine and confront theory and practice to, in fact, produce scientific knowledge."
  },
  {
    "objectID": "posts/box_1976/index.html#footnotes",
    "href": "posts/box_1976/index.html#footnotes",
    "title": "Science and Statistics: a brief review",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nIn his argument, the author addresses Science in general. Ultimately, we must keep in mind that this proposition does not necessarily encompass all scientific disciplines. Nevertheless, we know that his concern is with the Exact Sciences in general, especially Statistics.‚Ü©Ô∏é\n‚ÄúMathematistry is characterized by development of theory for theory‚Äôs sake which since it seldom touches down with practice, has a tendency to redefine the problem rather than solve it.‚Äù (Box 1976, 798).‚Ü©Ô∏é"
  },
  {
    "objectID": "projects/data-visualization/index.html",
    "href": "projects/data-visualization/index.html",
    "title": "Data Visualization",
    "section": "",
    "text": "Sketch of Visualizations\nVisualization Project\nExploratory Data Analysis"
  },
  {
    "objectID": "projects/data-visualization/index.html#assignments",
    "href": "projects/data-visualization/index.html#assignments",
    "title": "Data Visualization",
    "section": "",
    "text": "Sketch of Visualizations\nVisualization Project\nExploratory Data Analysis"
  },
  {
    "objectID": "projects/data-visualization/index.html#projects",
    "href": "projects/data-visualization/index.html#projects",
    "title": "Data Visualization",
    "section": "Projects",
    "text": "Projects\n\nProject 1: Voc√™ em Dados\nProject co-developed with Ana Carolina Erthal and Guilherme de Melo.\nSee the project here.\n\n\nProject 2: Visual F1\nProject co-developed with Ana Carolina Erthal and Guilherme de Melo.\nSee the project here."
  },
  {
    "objectID": "projects/deep-learning/index.html",
    "href": "projects/deep-learning/index.html",
    "title": "Deep Learning",
    "section": "",
    "text": "Assignment 1: Transfer Learning (10/10)\nAssignment 2: Semantic Segmentation (10/10)\nAssignment 3: Action Recognition (10/10)\nAssignment 4: Generative Adversarial Networks + Autoencoders (10/10)\nAssignment 5: Deep \\(k\\)-Means (10/10)\nPresentation: YUN, S. et al.¬†Graph Transformer Networks. In: NeurIPS, 2019. [pdf] [slides]\nAll notebooks were ran on Google Colab.\nThe repository also contains the cheatsheets folder with some useful concepts of Deep Learning I have written down during the course.\n\n\n\nCitationBibTeX citation:@online{lamarca2023,\n  author = {Lamarca, Felipe and Carolina Erthal, Ana},\n  title = {Deep {Learning}},\n  date = {2023-12-05},\n  url = {https://github.com/felipelmc/Deep-Learning},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nLamarca, Felipe, and Ana Carolina Erthal. 2023. ‚ÄúDeep\nLearning.‚Äù December 5, 2023. https://github.com/felipelmc/Deep-Learning."
  },
  {
    "objectID": "projects/projects.html",
    "href": "projects/projects.html",
    "title": "‚öôProjects",
    "section": "",
    "text": "SciELO-Summarizer\n\n\n\n\n\n\nComputational Social Sciences\n\n\nDeep Learning\n\n\n\nSciELO-Summarizer consists of a summarizer for scientific articles in Portuguese. It scrapes the content of the article from the SciELO website and generates a personalized summary for the user using Large Language Models (LLMs), especifically Llama3. \n\n\n\n\n\nJul 15, 2024\n\n\nFelipe Lamarca, Claudia Fernandes, Daniel Zacarias, Gabriellen Carmo, Lauriano Benazzi, Marcelle Amaral, Talita Ribeiro\n\n\n\n\n\n\n\n\n\n\n\n\nDeep Learning\n\n\n\n\n\n\nDeep Learning\n\n\n\nAssignments and presentation developed in the scope of the Deep Learning discipline, taught by Professor D√°rio Oliveira (FGV EMAp). Co-authored with @anacarolerthal, whom I thank for the ongoing partnership. \n\n\n\n\n\nDec 5, 2023\n\n\nFelipe Lamarca, Ana Carolina Erthal\n\n\n\n\n\n\n\n\n\n\n\n\nDataGrid\n\n\n\n\n\n\nAlgorithms\n\n\n\nImplementation of search, sorting & selection algorithms to build an efficient datagrid. Project developed within the scope of the Algorithm Design and Analysis discipline, lectured by Professor Thiago Pinheiro de Ara√∫jo (FGV EMAp). \n\n\n\n\n\nOct 18, 2023\n\n\nFelipe Lamarca, Cristiano Larr√©a\n\n\n\n\n\n\n\n\n\n\n\n\nStatistical Modeling\n\n\n\n\n\n\nStatistics\n\n\nComputational Social Sciences\n\n\n\nThis repository gathers the data, scripts, and analyses conducted for the final project of the Statistical Modeling course, taught by Professor Luiz Max Fagundes de Carvalho (FGV EMAp) (@maxbiostat). The objective was to apply modeling, inference, and prediction techniques, learned throughout this course and the Statistical Inference course, to real-world data. \n\n\n\n\n\nJul 15, 2023\n\n\nFelipe Lamarca\n\n\n\n\n\n\n\n\n\n\n\n\nMachine Learning\n\n\n\n\n\n\nMachine Learning\n\n\nStatistics\n\n\n\nThis repository contains all the assignments and the project I did for the Machine Learning course at the School of Applied Mathematics of the Getulio Vargas Foundation (FGV EMAp). The course was taught by Professor Diego Mesquita. \n\n\n\n\n\nJul 5, 2023\n\n\nFelipe Lamarca\n\n\n\n\n\n\n\n\n\n\n\n\nData Visualization\n\n\n\n\n\n\nData Visualization\n\n\n\nRepository where I keep all the assignments and projects developed in the scope of the Data Visualization discipline, taught by Professor Jorge Poco (@jpocom) (FGV EMAp). \n\n\n\n\n\nJun 30, 2023\n\n\nFelipe Lamarca, Ana Carolina Erthal, Guilherme de Melo\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "projects/statistical-modeling/index.html",
    "href": "projects/statistical-modeling/index.html",
    "title": "Statistical Modeling",
    "section": "",
    "text": "I chose to analyze the electoral dynamics for the position of federal deputy in the 2022 elections. Specifically, I explore multilevel (hierarchical) models, logistic regression, and model evaluation methods, such as AUC, AIC, accuracy, and \\(R^2\\). Additionally, I engage with part of the Political Science literature that uses Statistical Modeling techniques to extract information about Brazilian elections.\nThis work resulted in this report, the summary of which is as follows:"
  },
  {
    "objectID": "projects/statistical-modeling/index.html#about-the-project",
    "href": "projects/statistical-modeling/index.html#about-the-project",
    "title": "Statistical Modeling",
    "section": "",
    "text": "I chose to analyze the electoral dynamics for the position of federal deputy in the 2022 elections. Specifically, I explore multilevel (hierarchical) models, logistic regression, and model evaluation methods, such as AUC, AIC, accuracy, and \\(R^2\\). Additionally, I engage with part of the Political Science literature that uses Statistical Modeling techniques to extract information about Brazilian elections.\nThis work resulted in this report, the summary of which is as follows:"
  },
  {
    "objectID": "projects/statistical-modeling/index.html#who-wants-to-be-a-deputy-a-multilevel-analysis-of-the-2022-elections-for-the-chamber-of-deputies",
    "href": "projects/statistical-modeling/index.html#who-wants-to-be-a-deputy-a-multilevel-analysis-of-the-2022-elections-for-the-chamber-of-deputies",
    "title": "Statistical Modeling",
    "section": "Who Wants to Be a Deputy? A Multilevel Analysis of the 2022 Elections for the Chamber of Deputies",
    "text": "Who Wants to Be a Deputy? A Multilevel Analysis of the 2022 Elections for the Chamber of Deputies\nWhat increases a candidate‚Äôs chances of being elected? The specialized Political Science literature has sought to answer this question through various approaches over time. This work provides a statistical analysis of the 2022 electoral data to evaluate what impacts the chances of federal deputy candidates being elected in Brazil. Statistical modeling techniques are applied, including multilevel logistic regression models and metrics for evaluating the explanatory and predictive capacity of models. The results suggest that campaign expenditures, with variations between parties, account for a significant portion of the results at the polls.\nKeywords: Legislative Elections; Logistic Regression; Multilevel Models; Model Evaluation.\nThe work has been completed and received the highest grade."
  },
  {
    "objectID": "my-work/my-work.html#current-role",
    "href": "my-work/my-work.html#current-role",
    "title": "üë®üèª‚ÄçüíªMy work",
    "section": "üë®üèª‚Äçüíª Current Role",
    "text": "üë®üèª‚Äçüíª Current Role\n\nData Scientist & Researcher @ Instituto Rio21\n\nScope: Data collection, analysis, and visualization, focusing on opinion polls and social surveys\nHighlighted Projects: Municipal Management Assessment Survey and Election Polls\nProject Partner: Alian√ßa CentroRio, improving city life through data on conservation and security\nTechnical Skills: Geo-referencing, interactive maps, dashboards, statistical analysis\n\n\n\nFreelance Consulting\n\nExpertise Provided: Data science, social science insights, and policy analysis for diverse clients.\nNotable Clients:\n\nFunda√ß√£o Roberto Marinho\nArtplan\nInstituto Vini.Jr\nFGV\nCEBRAP\n\nTech Stack: Python, R, SQL, Statistics, Machine Learning, Deep Learning.\n\nYou can explore my open-source projects here."
  },
  {
    "objectID": "my-work/my-work.html#teaching-experience",
    "href": "my-work/my-work.html#teaching-experience",
    "title": "üë®üèª‚ÄçüíªMy work",
    "section": "üè´ Teaching Experience",
    "text": "üè´ Teaching Experience\n\n\n\nSemester\nCourse\nInstitution\nProfessor\n\n\n\n\n2024.2\nQuantitative Methods II\nFGV CPDOC\nJairo Nicolau, Ph.D.\n\n\n2020.2\nIntroduction to R\nFGV CPDOC\nJimmy Medeiros, Ph.D."
  },
  {
    "objectID": "my-work/my-work.html#training-workshops",
    "href": "my-work/my-work.html#training-workshops",
    "title": "üë®üèª‚ÄçüíªMy work",
    "section": "üìú Training & Workshops",
    "text": "üìú Training & Workshops\n\n[July 2024] Summer Institute in Computational Social Sciences (FGV ECMI)\n[July 2024] ML4Good (Centre pour la S√©curit√© de l‚ÄôIA and EffiSciences)"
  },
  {
    "objectID": "my-work/my-work.html#current-roles",
    "href": "my-work/my-work.html#current-roles",
    "title": "üë®üèª‚ÄçüíªMy work",
    "section": "",
    "text": "I help clients solve data-related problems, engaging in a wide range of projects. I have experience working on all stages of the data science pipeline, from the implementation of ETL pipelines to the development and integration of machine learning models, including GenAI applications. I also provide research support, such as data collection, analysis, and visualization.\nCurrent and past clients include NGOs, companies, public officials, politicians, and researchers from Brazilian think tanks and universities. If you think I can help you in any way, please reach out to me at felipe.lamarca@hotmail.com.\nYou can also explore my open-source projects here or on GitHub profile.\n\n\n\nI have been working at Instituto Rio21 since 2022, focusing on data collection, analysis, and visualization, with a special emphasis on opinion polls and social surveys. I have been involved in projects such as the Municipal Management Assessment Survey and Election Polls, while also working closely with Alian√ßa CentroRio to improve city life by turning data on conservation and security into intelligence.\nIn a daily basis, I use tools such as Python, R, SQL, and PowerBI to perform geo-referencing, interactive maps, dashboards, and statistical analysis.\n\n\n\nThe institutional goal of the Getulio Vargas Foundation is to estimulate the social and economic development of Brazil. The role of the Strategic Planning and Management Office (SPE) is to support FGV‚Äôs units in achieving institutional goals through KPI monitoring and fostering a data-driven culture.\nI have been working mainly on incorporating advanced GenAI techniques into the area‚Äôs data pipeline and identifying opportunities for automation and process improvement. I also support the development of presentations for C-level executives."
  },
  {
    "objectID": "my-work/my-work.html#teaching-assistant-experience",
    "href": "my-work/my-work.html#teaching-assistant-experience",
    "title": "üë®üèª‚ÄçüíªMy work",
    "section": "üè´ Teaching Assistant experience",
    "text": "üè´ Teaching Assistant experience\n\n\n\nSemester\nCourse\nInstitution\nProfessor\n\n\n\n\n2024.2\nQuantitative Methods II\nFGV CPDOC\nJairo Nicolau, Ph.D.\n\n\n2020.2\nIntroduction to R\nFGV CPDOC\nJimmy Medeiros, Ph.D."
  }
]